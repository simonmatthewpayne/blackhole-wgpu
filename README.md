This program renders a physically motivated picture of what a camera would see near a non‑spinning (Schwarzschild) black hole by following light itself rather than drawing polygons. For each pixel, we imagine a single photon leaving the camera and ask General Relativity where that photon would go. The shader converts the camera’s view ray into an initial four‑momentum in Schwarzschild coordinates and then integrates the null geodesic, the photon’s path in curved spacetime, forward using a fourth‑order Runge–Kutta scheme. The curvature enters through the Schwarzschild lapse α(r)=1−2M/r and its radial derivative; together with the usual Christoffel symbols they tell us how the time, radius, polar and azimuthal components of the photon’s momentum change along the way.

To keep the numerics stable and the picture faithful, the integrator adapts the step size with radius (smaller near the hole, larger far away), preserves the conserved energy E=αk^t by renormalizing the time component after each step, and uses pole‑safe trigonometry so that rays crossing over the poles (θ≈0 or π) do not blow up. Angles are wrapped to remain within sensible ranges, and crude guards terminate any ray that tries to produce infinities. None of this “cheats the physics”: the evolution still follows the null geodesic equations of motion; these are merely practical safeguards that keep a real‑time GPU implementation robust.

Every ray ends in one of two physical outcomes. If its radial coordinate slips inside the horizon (r≤2M), the photon is captured and the corresponding pixel is painted black: that set of directions on the camera forms the black‑hole shadow. If instead the photon climbs out to a very large radius (treated as “infinity”), we convert its outgoing direction back into a local 3‑vector and sample a simple background sky (currently just a vertical color gradient). Thus the bright regions are light that has threaded the gravitational field and escaped; the dark disk is light that could never have reached the camera from infinity because those directions inevitably fall into the hole.

What you see, even with a minimalist sky, is gravitational lensing: rays are bent by curvature, producing distortion, apparent magnification, and multiple‑pass trajectories around the hole before escape. Because this is a work‑in‑progress baseline, several effects are intentionally absent: spin (Kerr frame‑dragging), redshift and time‑delay coloring, emission/absorption from an accretion flow, and subpixel antialiasing or denoising. Those are natural next steps that can be layered on without changing the core idea: per‑pixel, null‑geodesic ray tracing in curved spacetime.

In short, this is not a rasterized impostor. It is a real‑time, GPU‑driven numerical integration of photon paths in a Schwarzschild geometry. The goal is accuracy first, then refinement using the same foundations you would use in an offline scientific renderer, but trimmed and stabilized so it is interactive and extensible.
